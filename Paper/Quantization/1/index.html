
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../../Lessons/Math/ODE/note/">
      
      
        <link rel="next" href="../2/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.39">
    
    
      
        <title>(Survey) Model Quantization for DNN in Image Classification - xueba's notebook</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.8c3ca2c6.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.75 1.75 0 0 1 1 7.775m1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2"/></svg>');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.5 1.75v11.5c0 .138.112.25.25.25h3.17a.75.75 0 0 1 0 1.5H2.75A1.75 1.75 0 0 1 1 13.25V1.75C1 .784 1.784 0 2.75 0h8.5C12.216 0 13 .784 13 1.75v7.736a.75.75 0 0 1-1.5 0V1.75a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25m13.274 9.537zl-4.557 4.45a.75.75 0 0 1-1.055-.008l-1.943-1.95a.75.75 0 0 1 1.062-1.058l1.419 1.425 4.026-3.932a.75.75 0 1 1 1.048 1.074M4.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5M4 7.75A.75.75 0 0 1 4.75 7h2a.75.75 0 0 1 0 1.5h-2A.75.75 0 0 1 4 7.75"/></svg>');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75M8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2"/></svg>');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M3.499.75a.75.75 0 0 1 1.5 0v.996C5.9 2.903 6.793 3.65 7.662 4.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873 10.794-.045 12.622.26 14.408.558 16 1.94 16 4.25c0 1.278-.954 2.575-2.44 2.734l.146.508.065.22c.203.701.412 1.455.476 2.226.142 1.707-.4 3.03-1.487 3.898C11.714 14.671 10.27 15 8.75 15h-6a.75.75 0 0 1 0-1.5h1.376a4.5 4.5 0 0 1-.563-1.191 3.84 3.84 0 0 1-.05-2.063 4.65 4.65 0 0 1-2.025-.293.75.75 0 0 1 .525-1.406c1.357.507 2.376-.006 2.698-.318l.009-.01a.747.747 0 0 1 1.06 0 .75.75 0 0 1-.012 1.074c-.912.92-.992 1.835-.768 2.586.221.74.745 1.337 1.196 1.621H8.75c1.343 0 2.398-.296 3.074-.836.635-.507 1.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.4 2.4 0 0 1-.507-.441 3.1 3.1 0 0 1-.633-1.248.75.75 0 0 1 1.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738 0 1.25-.615 1.25-1.25 0-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706 1.345-.46.92-.27 1.774.019 3.062l.042.19.01.05c.348.443.666.949.94 1.553a.75.75 0 1 1-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7 5.527c-.814-.68-1.75-1.462-2.692-2.619a3.7 3.7 0 0 0-1.023.88c-.406.495-.663 1.036-.722 1.508.116.122.306.21.591.239.388.038.797-.06 1.032-.19a.75.75 0 0 1 .728 1.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75 5.677V5.5c0-.984.48-1.94 1.077-2.664.46-.559 1.05-1.055 1.673-1.353z"/></svg>');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0"/></svg>');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13M6.92 6.085h.001a.749.749 0 1 1-1.342-.67c.169-.339.436-.701.849-.977C6.845 4.16 7.369 4 8 4a2.76 2.76 0 0 1 1.637.525c.503.377.863.965.863 1.725 0 .448-.115.83-.329 1.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6 6 0 0 0-.26.16 1 1 0 0 0-.276.245.75.75 0 0 1-1.248-.832c.184-.264.42-.489.692-.661q.154-.1.313-.195l.007-.004c.1-.061.182-.11.258-.161a1 1 0 0 0 .277-.245C8.96 6.514 9 6.427 9 6.25a.61.61 0 0 0-.262-.525A1.27 1.27 0 0 0 8 5.5c-.369 0-.595.09-.74.187a1 1 0 0 0-.34.398M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0M9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2.344 2.343za8 8 0 0 1 11.314 11.314A8.002 8.002 0 0 1 .234 10.089a8 8 0 0 1 2.11-7.746m1.06 10.253a6.5 6.5 0 1 0 9.108-9.275 6.5 6.5 0 0 0-9.108 9.275M6.03 4.97 8 6.94l1.97-1.97a.749.749 0 0 1 1.275.326.75.75 0 0 1-.215.734L9.06 8l1.97 1.97a.749.749 0 0 1-.326 1.275.75.75 0 0 1-.734-.215L8 9.06l-1.97 1.97a.749.749 0 0 1-1.275-.326.75.75 0 0 1 .215-.734L6.94 8 4.97 6.03a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018"/></svg>');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M9.504.43a1.516 1.516 0 0 1 2.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 0 1-.871.354h-.302a1.25 1.25 0 0 1-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004zm1.047 1.074L3.286 8.571A.25.25 0 0 0 3.462 9H6.75a.75.75 0 0 1 .694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0 0 12.538 7H9.25a.75.75 0 0 1-.683-1.06l2.008-4.418.003-.006-.004-.009-.006-.006-.008-.001q-.005 0-.009.004"/></svg>');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.5 3.5 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327q0 .15-.025.292c.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5q-.002.615-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A5 5 0 0 1 8 16a5 5 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5 5 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.7 1.7 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06m.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.17.17 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173"/></svg>');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M5 5.782V2.5h-.25a.75.75 0 0 1 0-1.5h6.5a.75.75 0 0 1 0 1.5H11v3.282l3.666 5.76C15.619 13.04 14.543 15 12.767 15H3.233c-1.776 0-2.852-1.96-1.899-3.458Zm-2.4 6.565a.75.75 0 0 0 .633 1.153h9.534a.75.75 0 0 0 .633-1.153L12.225 10.5h-8.45ZM9.5 2.5h-3V6c0 .143-.04.283-.117.403L4.73 9h6.54L9.617 6.403A.75.75 0 0 1 9.5 6Z"/></svg>');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 2.5h10.5a.75.75 0 0 1 0 1.5H1.75a.75.75 0 0 1 0-1.5m4 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5m0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5M2.5 7.75v6a.75.75 0 0 1-1.5 0v-6a.75.75 0 0 1 1.5 0"/></svg>');}</style>


  
  
  
  
  <style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20c-4.41 0-8-3.59-8-8s3.59-8 8-8 8 3.59 8 8-3.59 8-8 8m0-18A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10A10 10 0 0 0 12 2m1 5h-2v4H7v2h4v4h2v-4h4v-2h-4z"/></svg>');}</style>


    
    
      
    
    
      
    
    
      <link rel="stylesheet" href="../../../_css/extra.css">
    
      <link rel="stylesheet" href="https://cdn.tonycrane.cc/jbmono/jetbrainsmono.css">
    
      <link rel="stylesheet" href="https://cdn.tonycrane.cc/lxgw/lxgwscreen.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="teal">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="xueba&#39;s notebook" class="md-header__button md-logo" aria-label="xueba's notebook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            xueba's notebook
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              (Survey) Model Quantization for DNN in Image Classification
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="grey" data-md-color-accent="teal"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="cyan"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/XuebaStudy/notebook" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    XuebaStudy/notebook
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Lessons/How_1/" class="md-tabs__link">
          
  
    
  
  Lessons

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="./" class="md-tabs__link">
          
  
    
  
  Paper

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Music/places/" class="md-tabs__link">
          
  
    
  
  Music

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Tools/mkdocs/commands/" class="md-tabs__link">
          
  
    
  
  Tools

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Diary/Reflection/exams/" class="md-tabs__link">
          
  
    
  
  Diary

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Belief/charactors/%E7%81%B0%E4%B9%8B%E9%AD%94%E5%A5%B3%E4%BC%8A%E8%95%BE%E5%A8%9C/" class="md-tabs__link">
          
  
    
  
  Belief

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="xueba&#39;s notebook" class="md-nav__button md-logo" aria-label="xueba's notebook" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 22a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2h-6v7L9.5 7.5 7 9V2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2z"/></svg>

    </a>
    xueba's notebook
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/XuebaStudy/notebook" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    XuebaStudy/notebook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Lessons
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Lessons
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Lessons/How_1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to learn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Math
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Math
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Lessons/Math/ODE/note/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    常微分方程
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Paper
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Paper
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    量化模型
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            量化模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    (Survey) Model Quantization for DNN in Image Classification
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    (Survey) Model Quantization for DNN in Image Classification
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1 简介
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2 神经网络基本概念
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3 量化的概念
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 量化的概念">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 (网络组成中)量化的对象
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 何时量化
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-deterministicstochastic" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 确定性(deterministic)和随机(stochastic)量化
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 由分布看量化方法的水平
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      4 量化神经网络的训练
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 量化神经网络的训练">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-straight-through-estimator" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Straight-through Estimator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 权值更新
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 训练参数
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5 量化网络中的操作
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6" class="md-nav__link">
    <span class="md-ellipsis">
      6 量化网络中的层
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7" class="md-nav__link">
    <span class="md-ellipsis">
      7 评估与讨论
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8" class="md-nav__link">
    <span class="md-ellipsis">
      8 总结与展望
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    (Survey) Model Quantization and Hardware Acceleration for Vision Transformers
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Music
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Music
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../Music/places/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Music with places
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Music with places
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Music/places/ZJU_Mainlib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    浙大主图之夜
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    杂项
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            杂项
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Music/Others/mp3_visualization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    mp3->mp4(有声频谱)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tools
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Tools
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Mkdocs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            Mkdocs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/mkdocs/commands/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基础命令
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Tools/mkdocs/others/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    杂项
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Diary
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Diary
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_1" >
        
          
          <label class="md-nav__link" for="__nav_6_1" id="__nav_6_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reflection
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_1">
            <span class="md-nav__icon md-icon"></span>
            Reflection
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Diary/Reflection/exams/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    exams
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Diary/Reflection/interview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    interview
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../Diary/days_challenge/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    days_challenge
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            days_challenge
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Diary/days_challenge/24.8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    24.8
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Diary/days_challenge/24.10/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    24.10
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Diary/days_challenge/24.11/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    24.11
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Belief
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Belief
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_1" >
        
          
          <label class="md-nav__link" for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    charators
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1">
            <span class="md-nav__icon md-icon"></span>
            charators
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Belief/charactors/%E7%81%B0%E4%B9%8B%E9%AD%94%E5%A5%B3%E4%BC%8A%E8%95%BE%E5%A8%9C/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    灰之魔女伊蕾娜
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Belief/charactors/%E6%B4%9B%E7%90%AA%E5%B8%8C/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    洛琪希
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Belief/sentences/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sentences
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1 简介
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2 神经网络基本概念
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3 量化的概念
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 量化的概念">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 (网络组成中)量化的对象
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 何时量化
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-deterministicstochastic" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 确定性(deterministic)和随机(stochastic)量化
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 由分布看量化方法的水平
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      4 量化神经网络的训练
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4 量化神经网络的训练">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-straight-through-estimator" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Straight-through Estimator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 权值更新
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 训练参数
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      5 量化网络中的操作
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6" class="md-nav__link">
    <span class="md-ellipsis">
      6 量化网络中的层
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7" class="md-nav__link">
    <span class="md-ellipsis">
      7 评估与讨论
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8" class="md-nav__link">
    <span class="md-ellipsis">
      8 总结与展望
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<div><h1 id="_1"><a class="headerlink" href="#_1" title="Permanent link">¶</a></h1>
<h4 id="paper-a-comprehensive-survey-on-model-quantization-for-deep-neural-networks-in-image-classification">Paper: <a href="https://dl.acm.org/doi/10.1145/3623402" target="_blank">A Comprehensive Survey on Model Quantization for Deep Neural Networks in Image Classification</a><a class="headerlink" href="#paper-a-comprehensive-survey-on-model-quantization-for-deep-neural-networks-in-image-classification" title="Permanent link">¶</a></h4>
<div class="admonition abstract">
<p class="admonition-title">Abstract</p>
<ul>
<li>背景：Deep Neural Networks (DNNs) 在机器学习领域取得了重大进步，优点是精度高，缺点是存储消耗高，耗能高，这使得他们在有限的硬件资源上难以使用，量化 （Quantization）（the full-precision values are stored in low bit-width precision）即为解决这一难题的方法之一。</li>
<li>Quantization的优点：1. Quantization not only reduces memory requirements but also replaces high-cost operations with low-cost ones. 2. DNN quantization offers flexibility and efficiency in hardware design, making it a widely adopted technique in various methods.</li>
<li>贡献：<ol>
<li>Consequently, we present a comprehensive <strong>survey of quantization</strong> concepts and methods, with a focus on image classification. </li>
<li>We describe <strong>clustering-based quantization</strong> methods and explore <strong>the use of a scale factor</strong> parameter for approximating full-precision values. </li>
<li>Moreover, we thoroughly review <strong>the training of a quantized DNN</strong>, including the use of a straight-through estimator and quantization regularization. We explain the replacement of floating-point operations with low-cost bitwise operations in a quantized DNN and the sensitivity of different layers in quantization. </li>
<li>Furthermore, we highlight the evaluation <strong>metrics for quantization methods</strong> and important <strong>benchmarks in the image classification task</strong>. We also present the accuracy of the state-of-the-art methods on CIFAR-10 and ImageNet. </li>
<li>This article attempts to make the readers familiar with the basic and advanced concepts of quantization, introduce important works in DNN quantization, and highlight challenges for future research in this field.</li>
</ol>
</li>
</ul>
</div>
<h2 id="1">1 简介<a class="headerlink" href="#1" title="Permanent link">¶</a></h2>
<ol>
<li>Deep Convolutional Neural Network (DCNN) 成就斐然，但需要存储大量参数，进行大量计算（The main operation in DCNNs is multiply-accumulate
(MAC) in convolution and Fully Connected (FC) layers.），所以DNNs的加速很有必要。</li>
<li>In the beginning, the focus was on hardware optimization for processing speedup in DNN accelerators.<br>
-&gt;  Later, researchers concluded that compression
and software optimization of DNNs can be more effective before touching hardware.</li>
<li>The approaches in DNN compression:<ul>
<li><strong>Quantization</strong>: approximates the numerical network components with low bit-width precision.</li>
<li><strong>Pruning</strong>: removing unnecessary or less important connections within the network and
making a sparse network that reduces memory usage as well as computations.</li>
<li><strong>Low-rank approximation</strong>: an approach to simplify matrices and images, creates a
new matrix close to the weight matrix, which has lower dimensions and fewer computations in DNNs.</li>
<li><strong>Knowledge Distillation (KD)</strong>: employ a simpler model that exhibits generalization and accuracy comparable to the complex model.</li>
</ul>
<details class="note">
<summary>Advantages of quantization</summary>
<ul>
<li>High compression, with less accuracy reduction.</li>
<li>Flexibility<br>
-- Since quantization is not dependent on the network architecture, a quantization algorithm can be
applied to various types of DNNs. (Many quantization methods originally designed for
DCNNs are also used for Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks) .</li>
<li>Smaller number of cycles on hardware<br>
-- as high-cost floating-point operations are replaced with low-cost operations.</li>
<li>Reduces the cost of hardware accelerator design.<br>
-- For instance, in 1-bit quantization, a 32-bit floating-point multiplier can be replaced an XNOR operator, leading to a
cost reduction of 200 times in Xilinx FPGA</li>
<li>Contribute to controlling
overfitting.<br>
-- By simplifing parameters</li>
</ul>
</details>
</li>
<li>列举了一些关于各种Quantization方式的参考文献 (binary,mixed-precision,distillation-assisted,hardware-aware......)</li>
<li>概况后续内容 (同abstract)</li>
</ol>
<h2 id="2">2 神经网络基本概念<a class="headerlink" href="#2" title="Permanent link">¶</a></h2>
<ol>
<li>A DCNN consists of various types of layers, and the common layers include <strong>convolution layer, normalization layer, pooling layer, and FC layer</strong>.</li>
<li>
<ul>
<li>The main layer in DCNN is the convolution layer, which is formed in three
    dimensions. </li>
<li>This layer produces an output feature map by convolving multiple filters (weights)
with the input feature map. </li>
<li>There is weight sharing in the convolution layer, which means that
each weight is applied to different connections. </li>
<li>The majority of computationsin DCNNs are in this
layer due to its three-dimensional structure and <strong>weight sharing</strong>.</li>
</ul>
</li>
<li><strong>Weight sharing</strong> -&gt; a significant reduction in the number of parameters.<br>
-&gt; the majority of parameters in DCNNs are typically in the FC layers, where each neuron
is connected to all neurons in both the previous and next layers.</li>
<li>As <strong>the convolution and FC layers</strong>
contain the majority of <strong>computations and parameters in DCNNs</strong>, the primary focus is on these
layers in accelerators and compression techniques.</li>
</ol>
<h2 id="3">3 量化的概念<a class="headerlink" href="#3" title="Permanent link">¶</a></h2>
<p>Quantization is mapping values from a continuous space to a discrete space, where full-precision
values are mapped to new values with lower bit-width called quantization levels.</p>
<h3 id="31">3.1 (网络组成中)量化的对象<a class="headerlink" href="#31" title="Permanent link">¶</a></h3>
<ul>
<li>Each numerical component in neural networks can be quantized. ‌These components are typically divided into three main categories: weights, activations, and gradients.</li>
<li>Weights: the most common (But in
most cases, biases and other parameters, such as batch normalization parameters, are kept in full
precision in view of the fact that they include a minimal rate of neural network parameters, and the
quantization of them is less efficient in compression.)</li>
<li>Activations: 比weights的量化更困难 (While
weightsremain fixed after training, activations change during the inference phase according to the
input data.)，但仅仅对weights量化效率不高、内存使用率低, 故需共同量化</li>
<li>Gradients: 仅对训练时的加速有用，更难量化 (While
weightsremain fixed after training, activations change during the inference phase according to the
input data.)</li>
</ul>
<h3 id="32">3.2 何时量化<a class="headerlink" href="#32" title="Permanent link">¶</a></h3>
<table>
<thead>
<tr>
<th></th>
<th>Quantization-Aware Training (QAT)</th>
<th>Post-Training Quantization (PTQ).</th>
</tr>
</thead>
<tbody>
<tr>
<td>When</td>
<td>During training</td>
<td>After training</td>
</tr>
<tr>
<td>Defect</td>
<td>In a low bit-width precision quantized network, the convergence of the learning algorithm is challenging. -&gt; requires more iterations than the full-precision network for convergence. It needs customized solutions compatible with a discrete network.</td>
<td>A reduction in model accuracy. -&gt; needs retraining, fine-tuning agter quantization -&gt; repeat to reach an acceptable accuracy.</td>
</tr>
<tr>
<td>Speedup phase</td>
<td>the training and inference phases</td>
<td>the inference phase</td>
</tr>
</tbody>
</table>
<ul>
<li>The model accuracy in the QAT approach is commonly higher than in PTQ, because the trained
model is more compatible with the quantization process.</li>
</ul>
<h3 id="33-deterministicstochastic">3.3 确定性(deterministic)和随机(stochastic)量化<a class="headerlink" href="#33-deterministicstochastic" title="Permanent link">¶</a></h3>
<h4 id="deterministitc-quantization-methods">Deterministitc Quantization Methods<a class="headerlink" href="#deterministitc-quantization-methods" title="Permanent link">¶</a></h4>
<ul>
<li>Binary quantization:</li>
</ul>
<div class="arithmatex">\[b=\text{Sign}\left(x\right)=\begin{cases}+1\quad x\geq0\\-1\quad x&lt;0\end{cases}.\]</div>
<ul>
<li>Ternary quantization:</li>
</ul>
<div class="arithmatex">\[t=\begin{cases}+1&amp;x&gt;\Delta\\0&amp;|x|\leq\Delta\\-1&amp;x&lt;-\Delta\end{cases}.\]</div>
<ul>
<li>Others:</li>
</ul>
<div class="arithmatex">\[Q\left(x\right)=Sign\left(x\right).d.\min\left(round\left(\frac{\left|x\right|}d\right),\frac{M-1}2\right)\]</div>
<p>d represents the step size, and M is an odd number and determines the number
of quantization levels. Consequently, the quantization levels include zero, positive, and negative
values symmetrically.</p>
<div class="arithmatex">\[quantize_k=\frac1{2^k-1}round\left(\left(2^k-1\right)x\right),0\leq x\leq1\]</div>
<p>It maps the full-precision values in the range <span class="arithmatex">\(x\in[0,1]\)</span> to <span class="arithmatex">\(2^k\)</span> quantization levels within the same interval with step size <span class="arithmatex">\(\frac1{2^k-1}.\)</span> For <span class="arithmatex">\(k\)</span> bit-width, the quantization levels are <span class="arithmatex">\(L_q=\)</span> <span class="arithmatex">\(\{0,\frac1{2^k-1},\frac2{2^k-1},\ldots,1\}.\)</span> For example, for <span class="arithmatex">\(k=2\)</span>,there are <span class="arithmatex">\(2^2=4\)</span> quantization levels, which are <span class="arithmatex">\(L_q=\)</span> <span class="arithmatex">\(\{ 0\)</span>, ⅓, ⅔, <span class="arithmatex">\(1\} .\)</span></p>
<ul>
<li>Learned Quantization Network (LQ-Nets):</li>
</ul>
<div class="arithmatex">\[Q\left(x,v\right)=v^Te_l\ e_l\in\left\{-1,1\right\}^K,x\in\left(t_l,t_{l+1}\right).\]</div>
<p>x represents full-precision values, <span class="arithmatex">\(\nu\in\mathbb{R}^{K}\)</span> denotes the learnable floating-point basis vector, and <span class="arithmatex">\(e_{l}\)</span> is a <span class="arithmatex">\(k\)</span>-bit binary vector from <span class="arithmatex">\([-1,-1,\ldots,-1]\mathrm{~to~}[1,1,\ldots,1].\)</span></p>
<h4 id="stochastic-quantization-methods">Stochastic Quantization Methods<a class="headerlink" href="#stochastic-quantization-methods" title="Permanent link">¶</a></h4>
<div class="arithmatex">\[b=\begin{cases}+1\:p=\sigma\:(x)\\-1\:q=1-p\end{cases}.\]</div>
<div class="arithmatex">\[\sigma\left(x\right)=clip\left(\frac{x+1}2,0,1\right)=\max\left(0,\min\left(1,\frac{x+1}2\right)\right).\]</div>
<div class="arithmatex">\[\begin{cases}\mathrm{if~}w&gt;0:p\left(t=1\right)=w;\quad p\left(t=0\right)=1-w\\\mathrm{if~}w&lt;0:p\left(t=-1\right)=-w;p\left(t=0\right)=1+w\end{cases}.\]</div>
<h4 id="deterministic-and-stochastic-quantization-comparison">Deterministic and Stochastic Quantization Comparison.<a class="headerlink" href="#deterministic-and-stochastic-quantization-comparison" title="Permanent link">¶</a></h4>
<ul>
<li>Stochastic quantization has
shown <strong>better model generalization</strong> compared to deterministic quantization.</li>
<li>Implementation of stochastic quantization is <strong>more challenging and costly</strong> than deterministic quantization, particularly in hardware implementations, as it
requires a random bit generator.</li>
</ul>
<h3 id="34">3.4 由分布看量化方法的水平<a class="headerlink" href="#34" title="Permanent link">¶</a></h3>
<h4 id="341-uniform-and-non-uniform-quantization">3.4.1 Uniform and Non-uniform Quantization<a class="headerlink" href="#341-uniform-and-non-uniform-quantization" title="Permanent link">¶</a></h4>
<ul>
<li>In non-uniform quantization, the step size is determined according to the distribution of the full-precision values, which
makes it more complex and accurate than uniform quantization.</li>
</ul>
<figure>
  <img alt="Image title" src="../pictures/1.1.png"></figure>
<details class="note">
<summary>base-2 logarithm quantization: (x represents full-precision values)</summary>
<div class="arithmatex">\[Q\left(x\right)=\mathrm{Sign}\left(x\right)2^{round\left(\log_2\left|x\right|\right)}\]</div>
<p>-&gt; Logarithmic quantization allows the encoding of a larger range of numbers using the same storage in comparison with uniform quantization
by storing a small integer exponent instead of a floating-point number.</p>
<ul>
<li>
<p>Previous studies have revealed that weights in DCNNs often follow a normal distribution with
a mean of zero:
<figure markdown="span">
<img alt="Image title" src="../pictures/1.2.png"></figure>
-&gt; In logarithmic quantization, the quantization levels are denser for
values close to zero. Therefore, the distribution of quantization levelsin logarithmic quantization is
matched to the distribution of the full-precision weights in DCNNs, which leads to more accurate
quantization.</p>
</li>
<li>
<p>The base-2 logarithm quantization is naturally a representation of the binary system.
-&gt; it is well-matched to digital hardware and provides simple operations. </p>
</li>
</ul>
</details>
<h4 id="342-clustering-based-quantization">3.4.2 Clustering-based Quantization.<a class="headerlink" href="#342-clustering-based-quantization" title="Permanent link">¶</a></h4>
<figure>
  <img alt="Image title" src="../pictures/1.3.png"></figure>
<ul>
<li>DeepCompression method:<br>
using the k-means algorithm, where the weight values in a cluster are close to each other and mapped to the same quantization
level, which is the cluster center.</li>
<li>Single Level Quantization (SLQ) (for high bit-width precision ):<br>
the weights of each layer are
clustered separately using the k-means algorithm.<br>
-&gt; the clusters are grouped into
two categories based on quantization loss.<br>
-&gt; Low loss: quantization  ; High loss: retrain<br>
-&gt; These steps are repeated until all the weights are
quantized.<br>
-&gt; SLQ is not suitable for low bit-width quantization due to the small number of clusters, which leads to significant quantization loss.</li>
<li>Multiple Level Quantization (MLQ) (for 2-bit and 3-bit quantization.):<br>
-&gt; (Compared to SLQ) partitions weights not only in the width but <strong>also in the depth</strong> of the network. Layers are quantized iteratively
and incrementally (not at the same time).</li>
<li>Extended Single Level Quantization (ESLQ):<br>
changes cluster
centers as quantization levels to values with a specific type. For example, quantization levels are
mapped to the closest number in the form of Power Of Two (POT), making it well-suited for
implementation on FPGA platforms.</li>
</ul>
<details class="note">
<summary>Weighted entropy measure (for evaluating the quality of clustering)</summary>
<p><figure markdown="span">
<img alt="Image title" src="../pictures/1.4.png"></figure></p>
</details>
<details class="note">
<summary>Challenges of the clustering-based approach</summary>
<ol>
<li>Not suitable for implementation
in hardware and software due to their significant time complexity and computational requirements
for codebook reconstruction.  </li>
<li>The weights within a
cluster are not contiguous in memory, which leads to irregular memory accesses with long delays.  </li>
<li>The clustering-based approach is not suitable for activations quantization. (As weights are fixed during training, but activations are not)</li>
</ol>
</details>
<h4 id="343-scale-factor">3.4.3 Scale Factor.  (未总结)<a class="headerlink" href="#343-scale-factor" title="Permanent link">¶</a></h4>
<ul>
<li>讲了 Ternary Weight Network (TWN) method, Accurate Binary Convolutional
(ABC) method, Trained Ternary Quantization (TTQ), Explicit Loss-error-aware Quantization (ELQ) method......</li>
<li>The effect of scale factor model on convergence &amp; Challenges of using scale factor</li>
</ul>
<h2 id="4">4 量化神经网络的训练<a class="headerlink" href="#4" title="Permanent link">¶</a></h2>
<details class="note">
<summary>一个神经网络常用的训练方式--EBP (使用梯度下降、链式法则来调整网络参数)</summary>
<p><figure markdown="span">
<img alt="Image title" src="../pictures/1.5.png"></figure>
The weights between layers <span class="arithmatex">\(k\)</span> and <span class="arithmatex">\(j\)</span> are updated as  </p>
<div class="arithmatex">\[w_{kj}\left(n\right)=w_{kj}\left(n-1\right)-\gamma\Delta w_{kj},\:\Delta w_{kj}=\frac{\partial E}{\partial w_{kj}}=\sum_{i\in I_{j}}\left(\delta_{i}w_{ji}\right)h'\left(x_{i}\right)y_{k}=\delta_{j}y_{k}.\]</div>
<p>In the Equation, <span class="arithmatex">\(w_{kj}(n-1)\)</span> and <span class="arithmatex">\(w_{kj}(n)\)</span> indicate the weights between <span class="arithmatex">\(k\)</span> and <span class="arithmatex">\(j\)</span> layers before and after the update, respectively. <span class="arithmatex">\(\gamma\)</span> and <span class="arithmatex">\(\delta\)</span> are the learning rate and the error signal, respectively. <span class="arithmatex">\(x_i\)</span> and <span class="arithmatex">\(\gamma_i\)</span> are the inputs and outputs of layer <span class="arithmatex">\(i\)</span>, respectively, and <span class="arithmatex">\(h^\prime\)</span> denotes the derivative of the activation function.  </p>
</details>
<ul>
<li>然而使用该方法需要“连续、精确、不含驻点与不可微分点”的函数，而这在量化神经网络中往往不满足。<br>
为了解决这个问题，常使用STE方法来估计不可微函数的梯度。</li>
</ul>
<h3 id="41-straight-through-estimator">4.1 Straight-through Estimator<a class="headerlink" href="#41-straight-through-estimator" title="Permanent link">¶</a></h3>
<h4 id="411-ste-for-the-sign-function">4.1.1 STE for the <span class="arithmatex">\(Sign\)</span> function<a class="headerlink" href="#411-ste-for-the-sign-function" title="Permanent link">¶</a></h4>
<figure>
<img alt="Image title" src="../pictures/1.6.png"></figure>
<p>Examples:<br>
- Bitwise Neural Networks -- (a)<br>
- XNOR-Net and Binarized Neural   Networks (BNN) -- (b) -- hard tanh (Clip)<br>
- Bi-RealNet -- (c&amp;d)  </p>
<p>(The authors of the Bi-RealNet
paper concluded that higher-order functions require more complex computations, and thus, the
second-order function is acceptable)</p>
<h4 id="412-error-decay-estimator-ede">4.1.2 Error Decay Estimator (EDE)<a class="headerlink" href="#412-error-decay-estimator-ede" title="Permanent link">¶</a></h4>
<p>Information Retention Network (IR-Net) method  </p>
<div class="arithmatex">\[F\left(x\right)=k\tanh\left(tx\right),\]</div>
<p>where <span class="arithmatex">\(k\)</span> and <span class="arithmatex">\(t\)</span> are computed as</p>
<div class="arithmatex">\[t=T_{min}10^{\frac{i}{N}\times log\frac{Tmax}{T_{min}}},\:k=\max\left(\frac{1}{t},1\right).\]</div>
<p>In the Equation, <span class="arithmatex">\(i\)</span> determines the epoch number in <span class="arithmatex">\(N\)</span> epochs, <span class="arithmatex">\(T_{min}\)</span> is set to <span class="arithmatex">\(10^{-1}\)</span>,and <span class="arithmatex">\(T_{max}\)</span> is set to 10.EDE lies between the identity function <span class="arithmatex">\((y=x)\)</span> and the <span class="arithmatex">\(hard \  tanh\)</span> function. <span class="arithmatex">\(Hard \  tanh\)</span> is close to the <span class="arithmatex">\(Sign\)</span> function, but it discards the parameters outside the range [-1,1].  </p>
<details class="note">
<summary>Note</summary>
<p>Consequently, those parameters are not updated anymore, leading to a loss of information. However, the identity function covers the parameters outside [-1,1] but has a significant difference from the <span class="arithmatex">\(Sign\)</span> function, as indicated by the shaded area in Figure 12. EDE makes a tradeoff between the identity and hard tanh functions by varying parameters <span class="arithmatex">\(k\)</span> and <span class="arithmatex">\(t\)</span> during training. Initially, <span class="arithmatex">\(k\)</span> is bigger than 1,making EDE closer to the identity function. As the number of epochs increases, <span class="arithmatex">\(k\)</span> gradually tends towards 1, causing EDE transition to hard tanh for achieving more accurate estimation.
<figure markdown="span">
<img alt="Image title" src="../pictures/1.7.png" width="800"></figure>  </p>
</details>
<h4 id="413-quantized-relu-and-ste">4.1.3 Quantized ReLU and STE<a class="headerlink" href="#413-quantized-relu-and-ste" title="Permanent link">¶</a></h4>
<figure>
<img alt="Image title" src="../pictures/1.8.png"></figure>
<details class="note">
<summary>Log-tailed ReLU function</summary>
<div class="arithmatex">\[\tilde{Q}=\begin{cases}q_m+\log\left(x-\tau\right)\:x&gt;q_m\\x&amp;0&lt;x\leq q_m\:,\quad\tau=q_{m-1}\\0&amp;x\leq0\end{cases}\]</div>
</details>
<ul>
<li>The derivative of <strong>Half-Wave Gaussian Quantization (HWGQ)</strong> is zero.</li>
<li>HWGQ is bounded to
qm for x&gt;0, whereas <strong>Vanilla ReLU</strong> tends to infinity. Consequently, using Vanilla ReLU in the
backward pass leads to inaccurate gradients and unstable learning during training.</li>
<li>In <strong>Clipped ReLU</strong>,
the weak point of the Vanilla ReLU is modified by setting the gradient to zero for x≥qm. The idea behind this modification
comes from the fact that the frequency of the large values is commonly low, and these values are
interpreted as outliers.</li>
<li>Experimental results in the HWGQ method  show that <strong>Log-tailed ReLU</strong>
achieves higher accuracy in AlexNet compared to Clipped ReLU. However, <strong>Clipped ReLU</strong> achieves
superior performance compared to Log-tailed ReLU in VGGNet-variant and ResNet-18, which are
deeper than AlexNet.  </li>
</ul>
<h4 id="414-bounded-rectifier-and-ste">4.1.4 Bounded rectifier and STE<a class="headerlink" href="#414-bounded-rectifier-and-ste" title="Permanent link">¶</a></h4>
<details class="note">
<summary>Note</summary>
<p>In the ABC method , a bounded rectifier activation function
was proposed for mapping the full-precision activations to the range [0,1] as</p>
<div class="arithmatex">\[h_v\left(x\right)=clip\left(x+v,0,1\right)=\begin{cases}1&amp;x+v&gt;1\\x+v&amp;0&lt;x+v&lt;1\\0&amp;x+v&lt;0\end{cases}.\]</div>
<p>In Equation represents a trainable shift parameter. After mapping the values to the range<br>
[0,1],Equation is utilized for binarization as</p>
<div class="arithmatex">\[A=H_\upsilon\left(R\right)=2\mathbb{I}_{h_\upsilon\left(R\right)\geq0.5}-1=\begin{cases}+1\:h_\upsilon\geq0.5\\-1\:h_\upsilon&lt;0.5\end{cases}.\]</div>
<p>In Equation, l indicates the Indicator function. In the backward pass, STE is applied, and the
gradient is computed as</p>
<div class="arithmatex">\[\frac{\partial c}{\partial R}=\frac{\partial c}{\partial A}\mathbb{I}_{0\leq R-v\leq1}.\]</div>
</details>
<h4 id="415-parametric-quantization-function-and-ste">4.1.5 Parametric quantization function and STE<a class="headerlink" href="#415-parametric-quantization-function-and-ste" title="Permanent link">¶</a></h4>
<details class="note">
<summary>Note</summary>
<div class="arithmatex">\[y=PACT\left(x\right)=0.5\left(\left|x\right|-\left|x-\alpha\right|+\alpha\right)=\begin{cases}0\:x\in\left(-\infty,0\right)\\x\:x\in\left[0,\alpha\right)\\a\:x\in\left[\alpha,+\infty\right)\end{cases}.\]</div>
<p>(45)</p>
<p>The PACT function maps the full-precision activations to the range [0, <span class="arithmatex">\(\alpha].\)</span> Then the output of
the PACT function is quantized to <span class="arithmatex">\(k\)</span> bit-width precision using Equation (46).</p>
<div class="arithmatex">\[y_q=round\left(y\frac{2^k-1}\alpha\right)\frac\alpha{2^k-1}\]</div>
<p>(46)</p>
<p>If <span class="arithmatex">\(\alpha\)</span> is equal to 1,then the PACT function corresponds to the bounded rectifier function with <span class="arithmatex">\(\upsilon=0\)</span> in the ABC method [117]. The optimum <span class="arithmatex">\(\alpha\)</span> is found during training for minimizing the accuracy drop in quantization. It should be noted that the optimum value varies across different layers and models. Since Equation (46) is not differentiable, STE is employed for updating <span class="arithmatex">\(\alpha:\)</span></p>
<div class="arithmatex">\[\frac{\partial y_q}{\partial\alpha}=\frac{\partial y_q}{\partial y}\frac{\partial y}{\partial\alpha}=\begin{cases}0&amp;x\in(-\infty,\alpha)\\1&amp;x\in[\alpha,+\infty)\end{cases}.\]</div>
<p>(47)</p>
<p>The training is dependent on the value of <span class="arithmatex">\(\alpha.\)</span>If the initial value of <span class="arithmatex">\(\alpha\)</span> is too small, then, according to Equation (47), most activations will fall in the range of non-zero gradient, causing frequent changes in the value of <span class="arithmatex">\(\alpha\)</span> during training and leading to low model accuracy. However, if the initial value of <span class="arithmatex">\(\alpha\)</span> is too large, then the gradient will be zero for the majority of activations, leading to small gradients and the risk of gradient vanishing in the EBP algorithm. To address this, <span class="arithmatex">\(\alpha\)</span> is initialized with a large value that is not excessively large and then reduced using L2-norm regularization.
Although the effectiveness of STE has been demonstrated in practice through the results of previous works, there is still a concern regarding the lack of theoretical proof for its performance. Therefore, in recent years, some researchers have made efforts to theoretically justify the performance of STE [138, 139] . 
Table 3 summarizes the forward quantization function and its estimator in the backward pass
using STE for several previous works.</p>
</details>
<h3 id="42">4.2 权值更新<a class="headerlink" href="#42" title="Permanent link">¶</a></h3>
<p><figure markdown="span">
<img alt="Image title" src="../pictures/1.9.png"></figure>  </p>
<ul>
<li>为防止无效update，常常在update weights<strong>过程中</strong>使用full-precision.</li>
</ul>
<h3 id="43">4.3 训练参数<a class="headerlink" href="#43" title="Permanent link">¶</a></h3>
<ul>
<li>In quantized networks, a smalel learning rate often yields better.</li>
</ul>
<h4 id="432-network-structure">4.3.2 Network Structure:<a class="headerlink" href="#432-network-structure" title="Permanent link">¶</a></h4>
<ul>
<li>Sometimes structural adjustments are necessary for the neural network after quantization.</li>
</ul>
<details class="example">
<summary>example</summary>
<p>For instance, the max-pooling layer in some binary DNNs is displaced. In
DCNNs, a max-pooling layer commonly comes immediately after the activation layer. However,
in a binary neural network, where the Sign function is used for the binarization of the activations,
placing the max-pooling layer immediately after the Sign function results in an output matrix containing only +1 elements, as the values in a binarized matrix are −1 and +1. This leads to a loss
of information.</p>
</details>
<h4 id="433-regelarization">4.3.3 Regelarization:<a class="headerlink" href="#433-regelarization" title="Permanent link">¶</a></h4>
<ul>
<li>In quantization, approximating weights with low bit-width precision acts as a regularizer, and pushing the weights toward zeros can lead to a significant drop
in accuracy.  </li>
</ul>
<details class="note">
<summary>some approaches</summary>
<ul>
<li>Bit-level Sparsity Quantization (BSQ) suggested a regularization for mixed-precision quantization.  </li>
<li>a periodic regularization to push the full-precision weights toward the quantization levels.  </li>
<li>Tang et al. introduced a new regularization for binary quantization:</li>
</ul>
<div class="arithmatex">\[
J\left(W,b\right)=L\left(W,b\right)+\lambda\sum_{l=1}^L\sum_{i=1}^{N_l}\sum_{j=1}^{M_l}\left(1-\left(W_{l,ij}\right)^2\right)\\J\left(W,b\right)=L\left(W,b\right)+\lambda\sum_{l=1}^L\sum_{i=1}^{N_l}\sum_{j=1}^{M_l}\left(1-\left(W_{l,ij}\right)^2\right)\]</div>
<p>In Equation, <span class="arithmatex">\(L(W,b)\)</span> represents the loss function, and the second term denotes the regularization relation. <span class="arithmatex">\(L\)</span> indicates the number of layers. <span class="arithmatex">\(N_l\)</span> and <span class="arithmatex">\(M_l\)</span> are the dimensions of the weight matrix in layer <span class="arithmatex">\(\iota\)</span> The parameter <span class="arithmatex">\(\lambda\)</span> controls the effect of the loss function and regularization term.
<figure markdown="span">
- 
<img alt="Image title" src="../pictures/1.10-1.png"></figure>
<figure markdown="span">
<img alt="Image title" src="../pictures/1.10-2.png"></figure></p>
</details>
<h2 id="5">5 量化网络中的操作<a class="headerlink" href="#5" title="Permanent link">¶</a></h2>
<blockquote>
<p>讨论了在深度卷积神经网络（DCNNs）中实现乘累加（MAC）操作的效率问题。MAC操作是DCNNs中的主要计算任务，通常涉及大量的浮点数乘法和加法。量化技术通过将32位浮点数映射到更低比特宽度（如8位、4位、2位和1位）的值，从而在硬件平台上用更高效的整数或位操作替换高成本的浮点操作。  </p>
</blockquote>
<ul>
<li>量化操作：介绍了几种量化方法，包括对数量化和POT（Power Of Two）量化，这些方法通过位移动操作来替代浮点乘法，从而提高计算效率。  </li>
<li>位操作：讨论了如何在二进制神经网络中使用位操作（如XNOR和AND）来执行MAC操作，这在硬件实现中非常有效率。  </li>
<li>零水平量化：探讨了在量化中定义零水平可以减少计算量，因为乘以零的操作可以被省略。  </li>
</ul>
<h2 id="6">6 量化网络中的层<a class="headerlink" href="#6" title="Permanent link">¶</a></h2>
<blockquote>
<p>分析了在DCNNs中量化不同层对预测准确性的影响。网络中的每层对量化的敏感性不同，这取决于层的结构和在网络中的位置。</p>
</blockquote>
<ul>
<li>第一层和最后一层：讨论了量化输入层和输出层对模型准确性的影响，这些层对量化特别敏感，因为它们直接关系到网络的输入和输出。  </li>
<li>混合精度量化：介绍了根据网络层的敏感性为每层分配不同比特宽度的方法。这种方法旨在在准确性和压缩率之间找到最佳权衡。  </li>
<li>层的重要性：讨论了如何评估每层在量化中的重要性，以及如何根据这些信息来决定每层的量化精度。  </li>
</ul>
<h2 id="7">7 评估与讨论<a class="headerlink" href="#7" title="Permanent link">¶</a></h2>
<p>（含大量数据、表格，讨论对比了各神经网络在不同数据集上的表现）</p>
<h2 id="8">8 总结与展望<a class="headerlink" href="#8" title="Permanent link">¶</a></h2>
<details class="abstract">
<summary>Abstract</summary>
<ul>
<li>In this article, we surveyed the previous quantization works in the image classification task. The
basic and advanced concepts of DCNN quantization were discussed, as well as the most important
methods and approaches in this field, along with their advantages and challenges. Some previous
works perform quantization on both weights and activations, offering a higher compression rate
and employing lower-cost operations compared to approaches that are quantized only weights.
However, quantization of activations is more challenging compared to weights, which is due to
the wide range of activations, the use of a non-differentiable activation function, the estimation
of activations during the backward pass, and the variation of activation values during inference.  </li>
<li>The QAT and PTQ methods were studied, and it is concluded that the QAT methods generally achieve higher accuracy than the PTQ methods in the inference phase. Training a quantized
DNN poses new challenges compared to a full-precision network since the units are discrete. Itcommonly requires additional iterations for convergence in contrast to training a full-precision
network, and adaptive training strategies are required to build an accurate model. For instance,
the adjustment of learning rate and regularization techniques can be different from the training in
the full-precision network.  </li>
<li>We discussed uniform and non-uniform quantization techniques and concluded that nonuniform quantization, especially the POT quantization approach, efficiently covers the distribution of full-precision values, which leads to enhanced accuracy. For decreasing quantization error,
it is important to allocate quantization levels to informative regions. Using the scale factor helps
in shifting the quantization levels to the most informative parts of data.  </li>
<li>Some previous methods have successfully achieved high accuracy on large-scale datasets, such
as ImageNet, when both weights and activations are quantized in low bit-width. However, quantization with a precision lower than 4 bits remains a challenging task, especially in deeper networks.
During the training of a quantized network, STE is commonly used for calculating gradients in the
backward pass. The noise resulting from gradient mismatch, due to inaccurate estimation, is amplified layer-by-layer from the end of the network to the initial layers. This amplification of noise
is more considerable in deeper networks compared to shallow networks. In the training, this noise
can have a negative impact on model convergence. Additionally, since the number of parameters
increases with the depth of the neural network, the range of parameters in the deeper networks is
wider than in shallow ones, and the quantization is more challenging. Accordingly, future works
should focus on addressing the quantization of weights and activations in deeper networks with
low bit-width, such as binary or ternary quantization.  </li>
<li>In this article, we discussed mixed-precision, which is currently an interesting approach in the
quantization of the DNNs. The main challenge in mixed-precision quantization is the exponential time complexity in finding the optimum bit-width for each layer. It is desirable for future
worksto develop solutionsthat can determine the optimum mixed-precision with polynomial time
complexity.</li>
</ul>
</details></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024-2024 <a href="https://github.com/XuebaStudy" target="_blank" rel="noopener">XuebaStudy</a>
    </div>
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.expand", "navigation.indexes", "navigation.top", "navigation.tracking", "navigation.path", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.525ec568.min.js"></script>
      
        <script src="../../../_js/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
        <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
      
    
  </body>
</html>