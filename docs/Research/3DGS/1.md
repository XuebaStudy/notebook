# 3D Gaussian Splatting for Real-Time Radiance Field Rendering
[Paper :material-cursor-default-click:](https://arxiv.org/abs/2308.04079){ .md-button }
[Code :material-cursor-default-click:](https://github.com/graphdeco-inria/gaussian-splatting){ .md-button }
??? note "运行code时 参考过的Blog"
    - [环境配置 & 训练](https://blog.csdn.net/weixin_64588173/article/details/138140240)
    - [环境配置 · VS 2022](https://blog.csdn.net/weixin_50923989/article/details/144488349?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7Ebaidujs_baidulandingword%7ECtr-2-144488349-blog-139175269.235%5Ev43%5Epc_blog_bottom_relevance_base2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7Ebaidujs_baidulandingword%7ECtr-2-144488349-blog-139175269.235%5Ev43%5Epc_blog_bottom_relevance_base2&utm_relevant_index=5)
    - [删除CUDA](https://blog.csdn.net/qq_62928482/article/details/139636706)
    - [降级CUDA](https://blog.csdn.net/qq_43308156/article/details/127479544)
!!! warning
    本文由 Kimi Ai 总结而成，内容可能存在偏差。 
     
    - [ ] 人工复核
## 1. 研究背景与动机
传统的3D场景表示方法（如网格和点云）虽然适合快速渲染，但难以实现高质量的视图合成（novel-view synthesis）。近年来，基于神经网络的连续场景表示方法（如NeRF）虽然能够生成高质量的视图，但训练和渲染成本高昂。例如，Mip-NeRF360（一种高质量的NeRF方法）需要长达48小时的训练时间，且渲染速度极慢（0.071fps）。因此，如何在保持高质量的同时实现快速训练和实时渲染，是当前研究的一个重要方向。

## 2. 研究方法
论文提出了三个关键创新点，以实现高质量的实时辐射场渲染：

### 2.1 3D高斯分布表示（3D Gaussian Representation）
论文使用3D高斯分布来表示场景，每个高斯分布由位置（mean）、各向异性协方差矩阵（anisotropic covariance matrix）、不透明度（opacity）和球谐系数（spherical harmonic coefficients）组成。这种表示方法继承了连续体积辐射场（continuous volumetric radiance fields）的优化特性，同时避免了在空空间（empty space）中的无效计算。
!!! note "为什么选择3D高斯分布？"
    3D高斯分布是一种连续的概率分布，具有以下优点：  

    - **灵活性和表达性**：3D高斯分布可以通过其均值（位置）、协方差矩阵（形状和方向）和不透明度（密度）来表示复杂的几何形状和外观。  
    - **可微性**：高斯分布是可微的，这意味着可以通过梯度下降等优化方法来调整其参数，以更好地拟合场景。  
    - **高效的渲染**：高斯分布可以被投影到2D平面上，形成“溅射”（splatting），并使用标准的图像混合（blending）技术进行渲染，这使得渲染过程非常高效。

**数学公式：**
3D高斯分布的定义：
$$
A(\mathbf{x}) = \exp\left(-\frac{1}{2} (\mathbf{x} - \mathbf{\mu})^T \Sigma^{-1} (\mathbf{x} - \mathbf{\mu})\right)
$$
其中，\(\mathbf{x}\) 是空间中的一个点，\(\mathbf{\mu}\) 是高斯分布的均值（位置），\(\Sigma\) 是协方差矩阵。

协方差矩阵的优化表示：
$$
\Sigma = R S S R^T
$$
其中，\(R\) 是旋转矩阵，\(S\) 是缩放矩阵。这种表示方式允许独立优化旋转和缩放，避免了直接优化协方差矩阵可能带来的问题（如数值不稳定）。

### 2.2 优化与密度控制（Optimization and Density Control）
论文通过交替优化3D高斯分布的参数（位置、协方差、不透明度和球谐系数）和自适应密度控制（adaptive density control），逐步增加或删除高斯分布，以更好地表示场景。优化过程中，论文使用了随机梯度下降（Stochastic Gradient Descent, SGD）方法，并引入了自适应学习率调度（exponential decay scheduling）。
!!! note "优化过程"
    优化的目标是调整3D高斯分布的参数，使其能够更好地拟合输入的多视图图像数据。优化过程包括以下几个步骤：

    1. **初始化**：从稀疏的SfM（Structure from Motion）点云开始，初始化3D高斯分布的位置、协方差矩阵、不透明度和球谐系数。
    2. **渲染与比较**：使用当前的3D高斯分布参数渲染图像，并与训练数据中的图像进行比较，计算损失函数。
    3. **梯度下降**：通过反向传播计算损失函数对参数的梯度，并使用梯度下降方法更新参数。
!!! note "密度控制"
    为了更好地表示场景，论文中引入了自适应密度控制策略，包括以下两个操作：

    1. **克隆（Clone）**：当检测到小尺度几何结构（如细长的物体）未被充分覆盖时，通过克隆现有的高斯分布来增加几何细节。
    2. **分裂（Split）**：当检测到大尺度几何结构（如背景区域）被一个大的高斯分布覆盖时，将该高斯分布分裂成两个较小的高斯分布，以更好地捕捉细节。

**数学公式：**
损失函数：
$$
L = (1 - \lambda) \text{L1} + \lambda \text{D-SSIM}
$$
其中，\(\lambda\) 是一个权重因子，用于平衡L1损失和结构相似性指数（D-SSIM）损失。

??? note "L1损失和结构相似性指数（D-SSIM）损失"
    **L1损失（L1 Loss）**
    >L1损失，也称为绝对误差损失（Mean Absolute Error, MAE），是衡量预测值与真实值之间差异的一种方法。它计算的是预测值与真实值之间差的绝对值的平均值。

    对于两个图像 \( I \) 和 \( J \)，其中 \( I \) 是目标图像，\( J \) 是预测图像，L1损失定义为：
    $$
    L1 = \frac{1}{N} \sum_{i=1}^{N} |I_i - J_i|
    $$
    其中：

    - \( N \) 是图像中像素的总数。
    - \( I_i \) 是目标图像在第 \( i \) 个像素处的值。
    - \( J_i \) 是预测图像在第 \( i \) 个像素处的值。
    - \( |I_i - J_i| \) 是两个像素值之间的绝对差。

    **优点**：

    - 对异常值（outliers）相对不敏感，因为它是基于绝对差而不是平方差。
    - 计算简单，易于实现。  

    **缺点**：

    - 在优化过程中，梯度可能不够平滑，尤其是在误差较小时，可能导致优化速度较慢。

    **应用场景**  
    L1损失常用于图像重建、图像超分辨率、图像去噪等任务中，特别是在需要保持图像边缘清晰度时效果较好。

    ---
    **结构相似性指数（D-SSIM）损失**
    >结构相似性指数（Structural Similarity Index, SSIM）是一种衡量两个图像结构相似性的指标。它不仅考虑像素值的差异，还考虑图像的亮度、对比度和结构信息。D-SSIM是SSIM的变体，通常用于损失函数中，表示为 \( 1 - \text{SSIM} \)，以便在优化过程中最小化损失。

    SSIM的计算公式如下：
    $$
    \text{SSIM}(I, J) = \frac{(2 \mu_I \mu_J + C_1)(2 \sigma_{IJ} + C_2)}{(\mu_I^2 + \mu_J^2 + C_1)(\sigma_I^2 + \sigma_J^2 + C_2)}
    $$
    其中：

    - \( \mu_I \) 和 \( \mu_J \) 分别是图像 \( I \) 和 \( J \) 的平均值。
    - \( \sigma_I \) 和 \( \sigma_J \) 分别是图像 \( I \) 和 \( J \) 的标准差。
    - \( \sigma_{IJ} \) 是图像 \( I \) 和 \( J \) 的协方差。
    - \( C_1 \) 和 \( C_2 \) 是用于稳定分母的常数，防止分母为零。

    D-SSIM损失定义为：
    $$
    \text{D-SSIM} = 1 - \text{SSIM}
    $$

    **优点**：

    - 能够更好地捕捉图像的结构和纹理信息，而不仅仅是像素值的差异。
    - 更符合人类视觉系统的感知特性，对图像质量的评估更为准确。

    **缺点**：

    - 计算相对复杂，需要计算图像的均值、标准差和协方差。
    - 在某些情况下，优化可能较慢，因为其梯度计算较为复杂。

    **应用场景**  
    D-SSIM损失常用于图像重建、图像超分辨率、图像去噪等任务中，特别是在需要保持图像结构和纹理信息时效果显著。

    ---
    **总结**
    >**L1损失**：适用于需要保持图像边缘清晰度的任务，计算简单，但对异常值相对不敏感。  
    **D-SSIM损失**：适用于需要保持图像结构和纹理信息的任务，更符合人类视觉系统的感知特性，但计算相对复杂。

    在实际应用中，可以根据具体任务的需求选择合适的损失函数。例如，对于需要同时保持图像边缘和结构信息的任务，可以将L1损失和D-SSIM损失结合起来使用，如在论文中提到的损失函数：
    $$
    L = (1 - \lambda) \text{L1} + \lambda \text{D-SSIM}
    $$
    其中，\(\lambda\) 是一个权重因子，用于平衡两种损失。

### 2.3 实时可微渲染器（Real-Time Differentiable Renderer）

#### 2.3.1 渲染算法
实时可微渲染器的核心是将3D高斯分布投影到2D平面上，并进行高效的混合。具体步骤如下：

1. **投影到2D**：将每个3D高斯分布投影到2D屏幕上，形成一个椭圆形的溅射（splat）。
2. **排序与混合**：使用GPU的快速排序算法对溅射进行深度排序，然后按照排序顺序进行混合，以确保正确的可见性顺序。
3. **反向传播**：在训练过程中，需要计算损失函数对每个高斯分布参数的梯度。通过跟踪每个像素的累积不透明度，可以高效地计算这些梯度。

**渲染过程中的颜色合成公式**：
$$
C = \sum_{i} T_i (1 - \exp(-\sigma_i \Delta x_i)) L_i
$$
其中：
- \(C\) 是最终像素颜色。  
- \(T_i\) 是第 \(i\) 个溅射的透射率，表示光线穿过该溅射时的衰减。  
- \(\sigma_i\) 是第 \(i\) 个溅射的密度。  
- \(\Delta x_i\) 是光线在该溅射中的步长。  
- \(L_i\) 是第 \(i\) 个溅射的颜色。  

#### 2.3.2 瓦片渲染（Tile-Based Rasterization）
为了进一步提高渲染效率，论文中采用了瓦片渲染技术。屏幕被划分为多个小的瓦片（tiles），每个瓦片独立处理。这样可以减少不必要的计算，并充分利用GPU的并行处理能力。

## 3. 实验结果
论文在多个公开数据集上进行了实验，包括Mip-NeRF360数据集、Tanks&Temples数据集和Deep Blending数据集。实验结果表明，该方法在训练时间和渲染质量上均优于或等于现有的最先进方法。

### 3.1 定量评估（Quantitative Evaluation）
- **PSNR（峰值信噪比）**：衡量渲染图像与目标图像之间的相似度，值越高表示相似度越高。
- **SSIM（结构相似性指数）**：衡量图像的结构相似性，值越接近1表示相似度越高。
- **LPIPS（感知相似性）**：衡量图像的感知相似性，值越低表示相似度越高。

### 3.2 定性评估（Qualitative Evaluation）
通过可视化渲染结果，论文展示了该方法在细节保留和背景处理上的优势。例如，在某些场景中，Mip-NeRF360可能会出现模糊或噪点，而该方法能够更清晰地渲染细节。

## 4. 限制与未来工作
尽管该方法在实时渲染和训练速度上取得了显著进展，但仍存在一些限制：

### 4.1 限制
- **伪影（Artifacts）**：在未被充分观察的场景区域，可能会出现伪影。
- **内存消耗**：由于需要存储大量的高斯分布参数，内存消耗较高。
- **优化稳定性**：在某些情况下，优化过程中可能会出现“漂浮”或“斑点”伪影。

### 4.2 未来工作
未来的工作方向可能包括：

- **内存优化**：通过压缩技术减少模型大小，降低内存消耗。
- **正则化策略**：引入更复杂的正则化策略，以改善未观察区域的渲染效果。
- **网格重建**：探索将3D高斯分布应用于网格重建，以更好地理解该方法在体积表示和表面表示之间的位置。
